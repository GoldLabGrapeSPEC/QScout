# -*- coding: utf-8 -*-

"""
/***************************************************************************
 pin_dropper
                                 A QGIS plugin
 Drops pins
 Generated by Plugin Builder: http://g-sherman.github.io/Qgis-Plugin-Builder/
                              -------------------
        begin                : 2020-09-29
        copyright            : (C) 2020 by Joshua Evans
        email                : joshuaevanslowell@gmail.com
 ***************************************************************************/

/***************************************************************************
 *                                                                         *
 *   This program is free software; you can redistribute it and/or modify  *
 *   it under the terms of the GNU General Public License as published by  *
 *   the Free Software Foundation; either version 2 of the License, or     *
 *   (at your option) any later version.                                   *
 *                                                                         *
 ***************************************************************************/
"""

__author__ = 'Joshua Evans'
__date__ = '2020-10-6'
__copyright__ = '(C) 2020 by Joshua Evans'

# This will get replaced with a git SHA1 when you do a git archive

__revision__ = '$Format:%H$'

import math
import numpy as np
import itertools
from time import time
from osgeo import gdal
import random
import re

from qgis.PyQt.QtCore import QCoreApplication, QVariant
from qgis.core import (QgsProcessing,
                       QgsFeatureSink,
                       QgsProcessingAlgorithm,
                       QgsProcessingParameterFeatureSource,
                       QgsProcessingParameterFeatureSink,
                       QgsProcessingParameterRasterLayer,
                       QgsProcessingParameterNumber,
                       QgsProcessingParameterString,
                       QgsProcessingParameterBoolean,
                       QgsWkbTypes,
                       QgsFields,
                       QgsField,
                       QgsFeature,
                       QgsGeometry,
                       QgsProject,
                       QgsCoordinateTransform,
                       QgsPointXY,
                       QgsProcessingParameterEnum,
                       QgsProcessingParameterFile,
                       QgsProcessingParameterDistance,
                       QgsProcessingParameterDefinition
                       )
DIRECTION_RIGHT = 0
DIRECTION_UP = 1
DIRECTION_LEFT = 2
DIRECTION_DOWN = 3
NUM_DIRECTIONS = 4
DIRECTIONS = (
    (1, 0),
    (0, 1),
    (-1, 0),
    (0, -1)
)

ROW_NAME = 'row'
COL_NAME = 'col'

# for converting from numpy types to QVariants used by QGIS or Python data types that go into the QVariants
DTYPE_CONVERSIONS = {
            '?': (QVariant.Bool, bool),
            'b': (QVariant.Int, int),
            'B': (QVariant.Int, int),
            'i': (QVariant.Int, int),
            'u': (QVariant.Int, int),
            'f': (QVariant.Double, float),
            'U': (QVariant.String, str)
        }

START_CORNERS = [
    "Bottom Left",
    "Bottom Right",
    "Top Left",
    "Top Right"
]

class PinDropperAlgorithm(QgsProcessingAlgorithm):
    """
    This is an example algorithm that takes a vector layer and
    creates a new identical one.

    It is meant to be used as an example of how to create your own
    algorithms and explain methods and variables used to do it. An
    algorithm like this will be available in all elements, and there
    is not need for additional work.

    All Processing algorithms should extend the QgsProcessingAlgorithm
    class.
    """

    # Constants used to refer to parameters and outputs. They will be
    # used when calling the algorithm from another algorithm, or when
    # calling from the QGIS console.

    #basics
    OUTPUT = 'OUTPUT'
    RASTER_INPUT = 'RASTER_INPUT'
    BOUND_BOX_INPUT = 'BOUND_BOX_INPUT'
    PATCH_SIZE_INPUT = 'PATCH_SIZE_INPUT'
    START_CORNER_INPUT = 'START_CORNER_INPUT'
    # row and point interval
    ROW_VECTOR_INPUT = 'R0W_VECTOR_INPUT'
    ROW_HEIGHT_INPUT = 'ROW_HEIGHT_INPUT'
    ROW_HEIGHT_STDEV_INPUT = 'ROW_HEIGHT_STDEV_INPUT'
    POINT_INTERVAL_INPUT = 'POINT_INTERVAL_INPUT'
    POINT_INTERVAL_STDEV_INPUT = 'POINT_INTERVAL_STDEV_INPUT'
    #overlay for comparisons between plants
    OVERLAY_BOX_RADIUS_INPUT = 'OVERLAY_BOX_RADIUS_INPUT'
    OVERLAY_MATCH_THRESHOLD_INPUT = 'OVERLAY_MATCH_THRESHOLD_INPUT'
    #parameters for searching for overlay matches
    SEARCH_NUM_ITERATIONS_INPUT = 'SEARCH_NUM_ITERATIONS_INPUT'
    SEARCH_ITERATION_SIZE_INPUT = 'SEARCH_ITERATION_SIZE_INPUT'
    #output field name
    DROP_DATALESS_POINTS_INPUT = 'DROP_DATALESS_POINTS_INPUT'
    DATA_SOURCE_INPUT = 'FIELD_NAME_INPUT'
    PANEL_SIZE_INPUT = 'PANEL_SIZE_INPUT'
    DATA_SOURCE_FIELDS_TO_USE = 'DATA_SOURCE_FIELDS_TO_USE'

    # testing parameters
    RATE_OFFSET_MATCH_FUNCTION_INPUT = 'RATE_OFFSET_MATCH_FUNCTION_INPUT'
    RATE_OFFSET_MATCH_FUNCTION_INPUT = 'RATE_OFFSET_MATCH_FUNCTION_INPUT'
    PRECISION_BIAS_COEFFICIENT_INPUT = 'PRECISION_BIAS_COEFFICIENT_INPUT'
    COMPARE_FROM_ROOT_INPUT = 'COMPARE_FROM_ROOT'


    def initAlgorithm(self, config):
        """
        Here we define the inputs and output of the algorithm, along
        with some other properties.
        """

        self.MATCH_FUNCTIONS = {
            "Regular": None,
            "Local Normalized Difference": self.rate_offset_match_local_normalized_difference,
            "Global Normalized Difference": self.rate_offset_match_global_normalized_difference,
            "Absolute Difference": self.rate_offset_match_absolute_difference,
            "Relative Match Count": self.rate_offset_match_relative_match_count,
            "Gradients": self.rate_offset_match_gradients,
            "Random": self.rate_offset_match_random
        }

        # raster layer. repeating pattern in the raster will be used to drop pins
        self.addParameter(
            QgsProcessingParameterRasterLayer(
                self.RASTER_INPUT,
                self.tr('Raster Layer'),
                [QgsProcessing.TypeRaster],
                optional=True
            )
        )
        # bounding box
        self.addParameter(
            QgsProcessingParameterFeatureSource(
                self.BOUND_BOX_INPUT,
                self.tr('Bounding Box'),
                [QgsProcessing.TypeVectorPolygon]
            )
        )

        # direction vector for rows
        self.addParameter(
            QgsProcessingParameterFeatureSource(
                self.ROW_VECTOR_INPUT,
                self.tr('Row Vector'),
                [QgsProcessing.TypeVectorLine],
            )
        )

        self.addParameter(
            QgsProcessingParameterFile(
                self.DATA_SOURCE_INPUT,
                self.tr("Input Data"),
                optional=True
            )
        )

        param = QgsProcessingParameterEnum(
            self.RATE_OFFSET_MATCH_FUNCTION_INPUT,
            self.tr("Rate Offset Match Function"),
            options=self.MATCH_FUNCTIONS,
            defaultValue=0  # nothing I write here makes any difference
        )
        param.setFlags(param.flags() | QgsProcessingParameterDefinition.FlagAdvanced)
        self.addParameter(param)

        param = QgsProcessingParameterBoolean(
            self.COMPARE_FROM_ROOT_INPUT,
            self.tr("Compare from Root"),
            defaultValue=False
        )
        param.setFlags(param.flags() | QgsProcessingParameterDefinition.FlagAdvanced)
        self.addParameter(param)


        param = QgsProcessingParameterString(
            self.DATA_SOURCE_FIELDS_TO_USE,
            self.tr("Fields to Use"),
            optional=True
        )
        param.setFlags(param.flags() | QgsProcessingParameterDefinition.FlagAdvanced)
        self.addParameter(param)

        param = QgsProcessingParameterNumber(
            self.PANEL_SIZE_INPUT,
            self.tr("Panel Size"),
            minValue=0,
            defaultValue=0
        )
        param.setFlags(param.flags() | QgsProcessingParameterDefinition.FlagAdvanced)
        self.addParameter(param)

        self.addParameter(
            QgsProcessingParameterBoolean(
                self.DROP_DATALESS_POINTS_INPUT,
                self.tr("Drop Data-less Points"),
                defaultValue=False  # should maybe change to false in production version
            )
        )

        # row height
        self.addParameter(
            QgsProcessingParameterDistance(
                self.ROW_HEIGHT_INPUT,
                self.tr('Row Spacing'),
                parentParameterName=self.BOUND_BOX_INPUT,
                minValue=0
            )
        )

        # point interval
        self.addParameter(
            QgsProcessingParameterDistance(
                self.POINT_INTERVAL_INPUT,
                self.tr('Point Interval'),
                parentParameterName=self.BOUND_BOX_INPUT,
                minValue=0
            )
        )

        # overlay box radius
        param = QgsProcessingParameterNumber(
            self.OVERLAY_BOX_RADIUS_INPUT,
            self.tr('Overlay Box Radius'),
            type=QgsProcessingParameterNumber.Integer,
            minValue=0,
            defaultValue=2
        )
        param.setFlags(param.flags() | QgsProcessingParameterDefinition.FlagAdvanced)
        self.addParameter(param)

        self.addParameter(
            QgsProcessingParameterNumber(
                self.OVERLAY_MATCH_THRESHOLD_INPUT,
                self.tr("Match Threshold"),
                type=QgsProcessingParameterNumber.Double,
                minValue=0,
                maxValue=1,
                defaultValue=.85,  # this number has absolutely no scientific or mathematical basis
            )
        )

        self.addParameter(
            QgsProcessingParameterEnum(
                self.START_CORNER_INPUT,
                self.tr("Start Corner"),
                options=START_CORNERS,
                defaultValue=0
            )
        )

        param = QgsProcessingParameterNumber(
            self.PATCH_SIZE_INPUT,
            self.tr('Maximum Patch Size'),
            type=QgsProcessingParameterNumber.Integer,
            minValue=0,
            defaultValue=2
        )
        param.setFlags(param.flags() | QgsProcessingParameterDefinition.FlagAdvanced)
        self.addParameter(param)

        #optional parameters
        param = QgsProcessingParameterNumber(
            self.ROW_HEIGHT_STDEV_INPUT,
            self.tr('Row Spacing Stdev'),
            type=QgsProcessingParameterNumber.Double,
            minValue=0,
            optional=True
        )
        param.setFlags(param.flags() | QgsProcessingParameterDefinition.FlagAdvanced)
        self.addParameter(param)

        param = QgsProcessingParameterNumber(
            self.POINT_INTERVAL_STDEV_INPUT,
            self.tr('Point Interval Stdev'),
            type=QgsProcessingParameterNumber.Double,
            minValue=0,
            optional=True
        )
        param.setFlags(param.flags() | QgsProcessingParameterDefinition.FlagAdvanced)
        self.addParameter(param)

        param = QgsProcessingParameterNumber(
            self.SEARCH_ITERATION_SIZE_INPUT,
            self.tr("Search Iteration Size"),
            type=QgsProcessingParameterNumber.Integer,
            minValue=2,
            defaultValue=5
        )
        param.setFlags(param.flags() | QgsProcessingParameterDefinition.FlagAdvanced)
        self.addParameter(param)

        param = QgsProcessingParameterNumber(
            self.SEARCH_NUM_ITERATIONS_INPUT,
            self.tr("Number of Search Iterations"),
            type=QgsProcessingParameterNumber.Integer,
            minValue=1,
            defaultValue=2
        )
        param.setFlags(param.flags() | QgsProcessingParameterDefinition.FlagAdvanced)
        self.addParameter(param)

        param = QgsProcessingParameterNumber(
            self.PRECISION_BIAS_COEFFICIENT_INPUT,
            self.tr("Precision Bias Coefficient"),
            type=QgsProcessingParameterNumber.Double,
            minValue=0,
            defaultValue=0

        )
        param.setFlags(param.flags() | QgsProcessingParameterDefinition.FlagAdvanced)
        self.addParameter(param)

        # We add a feature sink in which to store our processed features (this
        # usually takes the form of a newly created vector layer when the
        # algorithm is run in QGIS).
        self.addParameter(
            QgsProcessingParameterFeatureSink(
                self.OUTPUT,
                self.tr('Output layer')
            )
        )

    def load_params(self, parameters, context):
        # required parameters
        self.raster = self.parameterAsRasterLayer(parameters, self.RASTER_INPUT, context)
        self.bound_box_layer = self.parameterAsVectorLayer(parameters, self.BOUND_BOX_INPUT, context)
        self.overlay_box_radius = self.parameterAsDouble(parameters, self.OVERLAY_BOX_RADIUS_INPUT, context)
        self.col_w = self.parameterAsDouble(parameters, self.POINT_INTERVAL_INPUT, context)
        assert self.col_w > 0, "Point interval must be greater than zero."
        self.row_h = self.parameterAsDouble(parameters, self.ROW_HEIGHT_INPUT, context)
        assert self.row_h > 0, "Row spacing must be greater than zero."
        self.row_vector_layer = self.parameterAsVectorLayer(parameters, self.ROW_VECTOR_INPUT, context)
        # self.ignore_raster = self.parameterAsBoolean(parameters, self.IGNORE_RASTER_INPUT, context)

        # optional parameters
        row_h_stdev = self.parameterAsDouble(parameters, self.ROW_HEIGHT_STDEV_INPUT, context)
        point_interval_stdev = self.parameterAsDouble(parameters, self.POINT_INTERVAL_STDEV_INPUT, context)
        self.overlay_match_min_threshold = self.parameterAsDouble(parameters, self.OVERLAY_MATCH_THRESHOLD_INPUT,
                                                                  context)
        self.search_iter_count = self.parameterAsInt(parameters, self.SEARCH_NUM_ITERATIONS_INPUT, context) - 1
        self.search_iter_size = self.parameterAsInt(parameters, self.SEARCH_ITERATION_SIZE_INPUT, context)
        self.patch_size = self.parameterAsInt(parameters, self.PATCH_SIZE_INPUT, context)
        offset_func_idx = self.parameterAsEnum(parameters, self.RATE_OFFSET_MATCH_FUNCTION_INPUT, context)
        self.rate_offset_match = list(self.MATCH_FUNCTIONS.values())[offset_func_idx]
        self.compare_from_root = self.parameterAsBool(parameters, self.COMPARE_FROM_ROOT_INPUT, context)
        self.precision_bias_coeff = self.parameterAsDouble(parameters, self.PRECISION_BIAS_COEFFICIENT_INPUT, context)

        self.start_corner = self.parameterAsEnum(parameters, self.START_CORNER_INPUT, context)

        self.data_source = self.parameterAsFile(parameters, self.DATA_SOURCE_INPUT, context)
        self.drop_dataless_points = self.parameterAsBool(parameters, self.DROP_DATALESS_POINTS_INPUT, context)
        self.drop_dataless_points = self.drop_dataless_points or self.data_source is None

        assert self.search_iter_size % 2 == 1, "Search iteration size should be odd to include search centerpoint."

        assert self.raster is not None or self.rate_offset_match is None, "All rate functions except 'Regular' require" \
                                                                          "a raster layer."

        self.overlay_box_radius += .5

        if row_h_stdev > 0:
            self.row_h_stdev = row_h_stdev / self.row_h
        if point_interval_stdev > 0:
            self.col_w_stdev = point_interval_stdev / self.col_w

    def processAlgorithm(self, parameters, context, feedback):
        """
        Here is where the processing itself takes place.
        """

        # declare algorithm parameters, mainly just so we have them all in on place
        self._root = None
        self.bound_box = None
        self._defined_points = {}
        self._loose_ends = None
        self.row_h_geo_dx = 0
        self.row_h_geo_dy = 0
        self.col_w_geo_dx = 0
        self.col_w_geo_dy = 0
        self.col_w_stdev = .05
        self.row_h_stdev = .05
        self.overlay_box_radius = 0
        self.coords_mins = None
        self.coords_maxs = None
        # read parameters
        self.load_params(parameters, context)

        if self.rate_offset_match is not None:
            self.load_raster_data()

        # convert row vector to the same CRS as the bounding box
        row_vector_geom = list(self.row_vector_layer.getFeatures())[0].geometry()
        if self.row_vector_layer.crs().authid() != self.bound_box_layer.crs().authid():
            transform_context = QgsProject.instance().transformContext()
            coord_transformer = QgsCoordinateTransform(self.row_vector_layer.crs(), self.bound_box_layer.crs(), transform_context)
            row_vector_geom.transform(coord_transformer)

        assert self.raster is None or self.raster.crs().authid() == self.bound_box_layer.crs().authid(), \
            "Raster layer must have same CRS as bounds vectory layer."
        row_vector = row_vector_geom.asMultiPolyline()[0]
        start = row_vector[0]
        stop = row_vector[len(row_vector)-1]

        self.bound_box = list(self.bound_box_layer.getFeatures())[0].geometry()
        if self.bound_box.isMultipart():
            self.bound_box = self.bound_box.asGeometryCollection()[0]

        assert self.bound_box.contains(row_vector[0]), "Row vector should be within the bounding box."

        theta = math.atan2(stop[1] - start[1], stop[0] - start[0])

        self.row_h_geo_dx = math.cos(theta + math.pi / 2) * self.row_h
        self.row_h_geo_dy = math.sin(theta + math.pi / 2) * self.row_h
        self.col_w_geo_dx = math.cos(theta) * self.col_w
        self.col_w_geo_dy = math.sin(theta) * self.col_w

        assert not self.near_border((0, 0), *start), "Row vector should not be near the edge of the bounding box."

        # establish root for pin map
        self._root = PinDropperPin(0, 0, None, -1)
        self._loose_ends = {}
        self.drop_pin_at(self._root, *start)
        if self.rate_offset_match is not None:
            self._root_sample = PinDropperAlgorithm.Sample(*self._root.geoCoords(), self)
            assert self._root_sample.a is not None, "Entire root sample outside bounds despite not being near edge." \
                                                    "I have no idea how that can even happen."
            self_similarity = self.rate_offset_match(self._root_sample, self._root_sample)
            assert self_similarity > .975, "Self-similarity score: %s" % self_similarity  # allow some leeway for rounding errors

        # Compute the number of steps to display within the progress bar
        approx_total_calcs = self.bound_box.area() / ((self.row_h_geo_dx + self.col_w_geo_dx) * (self.row_h_geo_dy + self.col_w_geo_dy))

        feedback.setProgress(0)
        feedback.pushInfo("Starting area search")
        print("Debug log begin")

        itercount = 0
        # for debugging, you can change this value to have the algorithm stop before it's technically done
        max_points = approx_total_calcs * 2
        # max_points = 1
        while not self.is_complete() and self.population() < max_points:
            feedback.pushInfo("Iteration %d: %d loose ends" % (itercount, len(self._loose_ends)))
            self.id_points_iterate(feedback)
            itercount = itercount + 1

            # update progress
            feedback.setProgress(int(100 * self.population() / approx_total_calcs))
            feedback.setProgressText("%d / ~%d" % (self.population(), approx_total_calcs))

        # if the user has cancelled the process, stop everything else
        if feedback.isCanceled():
            return {self.OUTPUT: None}

        # patch holes. here be dragons
        if self.is_do_patches():
            holecount = self.patch_holes()
            if holecount > 0:
                feedback.pushInfo("Patched %n holes.")

        # 'relativize' the coordinates, so x and y both start at 1
        self.relativize_coords()

        data, attrs = self.load_input_data(parameters, context)

        out_fields = QgsFields()
        for n, dt in attrs:
            out_fields.append(QgsField(name=n, type=dt))

        # Retrieve the feature source and sink. The 'dest_id' variable is used
        # to uniquely identify the feature sink, and must be included in the
        # dictionary returned by the processAlgorithm function.
        (self.sink, dest_id) = self.parameterAsSink(
            parameters,
            self.OUTPUT,
            context,
            fields=out_fields,
            geometryType=QgsWkbTypes.Point,
            crs=self.bound_box_layer.crs(),
            sinkFlags=QgsFeatureSink.RegeneratePrimaryKey)

        # read values from source csv file
        # (for now generate random values from 1 to 5)

        # set output field values
        count = 0
        already_dropped = []
        not_dropped = []
        if data is not None:
            for entry in data:
                coords = (entry[self.input_col_attr_name], entry[self.input_row_attr_name])
                if coords in self._defined_points:
                    pin = self[coords]
                    vals = [DTYPE_CONVERSIONS[data.dtype[i].kind][1](entry[i]) for i in range(len(data.dtype))]
                    count = self.add_pin_to_output(pin, vals, count)
                    already_dropped.append(coords)
                else:
                    not_dropped.append(coords)

        if self.drop_dataless_points or data is None:
            for coords in self._defined_points:
                if coords not in already_dropped:
                    entry = [np.nan for _ in attrs]
                    entry[self.col_attr_idx] = int(coords[0])
                    entry[self.row_attr_idx] = int(coords[1])
                    count = self.add_pin_to_output(self[coords], entry, count)

        for d in not_dropped:
            feedback.pushInfo("Did not drop coordinates for %d, %d." % d)

        # Return the results of the algorithm. In this case our only result is
        # the feature sink which contains the processed features, but some
        # algorithms may return multiple feature sinks, calculated numeric
        # statistics, etc. These should all be included in the returned
        # dictionary, with keys matching the feature corresponding parameter
        # or output names.
        return {self.OUTPUT: dest_id}

    def load_raster_data(self):
        # init self params
        ds = gdal.Open(self.raster.dataProvider().dataSourceUri())
        assert ds is not None, "Raster layer data provider URI not accessable, or something like that. You probably " \
                               "forgot to tell the program not to use the Google Maps layer again."
        self.raster_data = np.stack([
            ds.GetRasterBand(band+1).ReadAsArray()
            for band
            in range(self.raster.dataProvider().bandCount())
        ], axis=-1)

        self.band_ranges = np.stack([
            np.amin(self.raster_data, axis=tuple(range(len(self.raster_data.shape) - 1))),
            np.amax(self.raster_data, axis=tuple(range(len(self.raster_data.shape) - 1)))
        ], axis=-1)

        blank_axes = self.band_ranges[:, 0] != self.band_ranges[:, 1]
        self.raster_data = np.transpose(self.raster_data[:, :, blank_axes], axes=(1, 0, 2))
        self.band_ranges = self.band_ranges[blank_axes, :]
        self.raster_transform = ds.GetGeoTransform()
        del ds  # save memory

    def load_input_data(self, parameters, context):

        attrs = []
        fields_to_use = self.parameterAsString(parameters, self.DATA_SOURCE_FIELDS_TO_USE, context)

        fields_to_use_list = []
        if fields_to_use.strip():
            fields_to_use_list = map(lambda x: x.strip(), fields_to_use.rsplit(','))

        # assign rating function
        if self.data_source.strip():
            fn = self.data_source
            # may raise exceptions. may have to improve descriptivensee of errors
            input_data = np.genfromtxt(fn, delimiter=',', names=True)
            # TODO: maybe put all of this in load_input_data eventually

            # read input data analysis parameters
            panel_size = self.parameterAsInt(parameters, self.PANEL_SIZE_INPUT, context)

            attrs = [(input_data.dtype.names[i], input_data.dtype[i])
                             for i in range(len(input_data.dtype))
                             if ((not fields_to_use.strip()) or input_data.dtype.names[i] in fields_to_use_list)]
            if panel_size > 0:
                attrs = attrs + [(COL_NAME, np.int16)]
                self.input_col_attr_name = COL_NAME
                self.col_attr_idx = len(attrs) - 1
            else:
                col_regex = "([_\-\w]?[Cc]ol.?)|(.?[Nn]umber.?)"
                self.input_col_attr_name, self.col_attr_idx = match_index(input_data.dtype.names, col_regex)
                assert self.col_attr_idx > -1, "No column in the attached file can ve identified as 'column' or 'number'." \
                                               "Tip: if your data has a column for panels, you need to specify the panel size."

            row_regex = "[_\-\w]?[Rr]ow"
            self.input_row_attr_name, self.row_attr_idx = match_index(input_data.dtype.names, row_regex)
            assert self.row_attr_idx > -1, "No column in the attached file can be identified as 'row'"

            attrs[self.row_attr_idx] = (attrs[self.row_attr_idx][0], np.dtype(np.int_))
            attrs[self.col_attr_idx] = (attrs[self.col_attr_idx][0], np.dtype(np.int_))

            data = np.full(shape=input_data.shape, dtype=np.dtype(attrs), fill_value=np.nan)

            x_mins, x_maxs, y_mins, y_maxs = self.calc_grid_dimensions()
            if panel_size > 0:
                panel_regex = ".?[Pp]anel.?"
                panel_attr_name, panel_attr_idx = match_index(input_data.dtype.names, panel_regex)
                assert panel_attr_idx > -1, "No column in the attached file can ve identified as 'panel'"
                vine_regex = ".?([Vv]ine)|([Pp]lant).?"
                vine_attr_name, vine_attr_idx = match_index(input_data.dtype.names, vine_regex)
                assert vine_attr_idx > -1, "No column in the attached file can ve identified as 'vine' or 'plant"
                data[self.input_col_attr_name] = panel_size * input_data[panel_attr_name] + input_data[vine_attr_name]
            else:
                negative_cols = input_data[self.input_col_attr_name] < 0
                x_data_neg = x_maxs[input_data[self.input_row_attr_name][negative_cols].astype(np.int_)] +\
                             input_data[self.input_col_attr_name][negative_cols]
                data[self.input_col_attr_name][negative_cols] = x_data_neg
                data[self.input_col_attr_name][negative_cols == False] = input_data[self.input_col_attr_name][negative_cols == False]

            y_max = np.amax(y_maxs)
            negative_rows = input_data[self.input_row_attr_name] < 0
            data[self.input_row_attr_name][negative_rows] = y_max + input_data[self.input_row_attr_name][negative_rows]
            data[self.input_row_attr_name][negative_rows == False] = input_data[self.input_row_attr_name][negative_rows == False]

            for dt_name, _ in attrs:
                if dt_name == self.input_col_attr_name or dt_name == self.input_col_attr_name:
                    continue
                data[dt_name] = input_data[dt_name]

        else:
            data = None
            if fields_to_use.strip():
                attrs = [(COL_NAME, np.dtype(np.int16)), (ROW_NAME, np.dtype(np.int16))]
                attrs.extend([(name, np.dtype(np.str)) for name in fields_to_use_list])
            else:
                attrs = [(COL_NAME, np.dtype(np.int16)), (ROW_NAME, np.dtype(np.int16)), ('data', np.dtype(np.str))]
            self.input_col_attr_name = COL_NAME
            self.col_attr_idx = 0
            self.input_row_attr_name = ROW_NAME
            self.row_attr_idx = 1

        out_attrs_types = [(name, DTYPE_CONVERSIONS[t.kind][0]) for name, t in attrs]

        return data, out_attrs_types

    def id_points_iterate(self, feedback):
        t_iter_begin = time()
        old_loose = {point: self._loose_ends[point] for point in self._loose_ends}
        self._loose_ends = {}
        pins_dropped = 0
        for loose_end in old_loose.values():
            if feedback.isCanceled():
                break
            success = self.drop_pin(loose_end)
            # feedback.pushInfo("Tried to drop pin at coords (%d, %d) - %s" %
            #                   (loose_end.x_index(), loose_end.y_index(), ("success" if success else "failure")))
            pins_dropped = pins_dropped + 1
        feedback.pushInfo("Checked %d pins in %f seconds!" % (pins_dropped, time() - t_iter_begin))

        # find "loose ends" that are actually defined points and merge them out
        loose_end_coords = list(self._loose_ends.keys())
        for coords in loose_end_coords:
            # if there exists a defined point with the same coords as the loose end
            if coords in self:
                # merge the loose end
                self[coords].merge_with_loose_end(self._loose_ends[coords])
                self._loose_ends.pop(coords)

        self.refresh_mins_maxs()

    def patch_holes(self):
        all_dropped_coords = self.points_as_array()

        holecount = 0
        for ridx in range(self.coords_mins[1], self.coords_maxs[1]):
            row = all_dropped_coords[:, all_dropped_coords[1, :] == ridx]
            r_min = np.amin(row[0, :])
            r_max = np.amax(row[0, :])
            row_w = r_max - r_min
            if row_w != row.size:
                for x in range(r_min, r_max):
                    coords = (x, ridx)
                    if coords not in self:
                        patch_success = self.patch_hole(coords)
                        holecount = holecount + 1 if patch_success else holecount

        return holecount

    def patch_hole(self, coords):
        coords = tuple(coords)
        assert coords not in self._defined_points

        borders = self.identify_nearest_bordering_points(coords)

        assert not all([b is None for b in borders]), "No borders found for point at %s" % (coords)

        # check if coords are on same row/column
        assert (borders[DIRECTION_RIGHT] is None or borders[DIRECTION_LEFT] is None) or borders[DIRECTION_RIGHT][1] == borders[DIRECTION_LEFT][1]
        assert (borders[DIRECTION_UP] is None or borders[DIRECTION_DOWN] is None) or borders[DIRECTION_UP][0] == borders[DIRECTION_DOWN][0]

        prospec_coords_x, prospec_coords_y, pin_point, hole_w, hole_h = None, None, None, None, None
        if borders[DIRECTION_RIGHT] is not None and borders[DIRECTION_LEFT] is not None:
            geo_distance = self.geo_coords_distance(borders[DIRECTION_LEFT], borders[DIRECTION_RIGHT])
            hole_w = self.idx_distance(borders[DIRECTION_RIGHT], coords, single_value=True)
            rel_from_start =  hole_w / self.idx_distance(borders[DIRECTION_RIGHT], borders[DIRECTION_LEFT], single_value=True)
            prospec_coords_x = self[borders[DIRECTION_RIGHT]].geoCoords() + geo_distance * rel_from_start

        # if spacing is vertical
        if borders[DIRECTION_UP] is not None and borders[DIRECTION_DOWN] is not None:
            geo_distance = self.geo_coords_distance(borders[DIRECTION_DOWN], borders[DIRECTION_UP])
            hole_h = self.idx_distance(borders[DIRECTION_UP], coords, single_value=True)
            rel_from_start =  hole_h / self.idx_distance(borders[DIRECTION_UP], borders[DIRECTION_DOWN], single_value=True)
            prospec_coords_y = self[borders[DIRECTION_UP]].geoCoords() + geo_distance * rel_from_start

        assert prospec_coords_x is not None or prospec_coords_y is not None

        # if the hole is larger than the maximum patch size, return False
        if (hole_w > self.patch_size or prospec_coords_x is None) and (hole_h > self.patch_size or prospec_coords_y is None):
            return False

        if prospec_coords_x is not None and prospec_coords_y is not None:
            pin_point = np.mean(np.stack([np.array(prospec_coords_x), np.array(prospec_coords_y)]), axis=0)
        elif prospec_coords_x is not None:
            pin_point = prospec_coords_x
        else:
            assert prospec_coords_y is not None
            pin_point = prospec_coords_y

        if coords not in self:
            self._defined_points[coords] = PinDropperPin(*coords, None, None)
        self.drop_pin_at(self[coords], *pin_point)
        # if hole was successfully patched, return true
        return True

    def identify_nearest_bordering_points(self, coords):
        borders = [coords, coords, coords, coords]

        # find nearest defines dpoint in each direction
        for direction in range(NUM_DIRECTIONS):
            while borders[direction] not in self._defined_points:  # scary while-loop
                borders[direction] = tuple(np.add(np.array(borders[direction]), np.array(DIRECTIONS[direction])))
                # if borders[direction] not in self._defined_points:
                if borders[direction][0] > self.coords_maxs[0] or \
                        borders[direction][1] > self.coords_maxs[1] or \
                        self.coords_mins[0] > borders[direction][0] or \
                        self.coords_mins[1] > borders[direction][1]:
                    borders[direction] = None
                    break

        return borders

    def relativize_coords(self):
        flip_rows = self.start_corner % 2 != 0
        flip_cols = self.start_corner > 1
        row_mins, row_maxs, col_mins, col_maxs = self.calc_grid_dimensions()
        points = self._defined_points.values()
        adjusted_points = {}
        for pin in points:
            # assume that each row starts at zero but that row numbering starts at the lowest row
            pin.relativize(row_mins[pin.y_index() - self.coords_mins[1]], row_maxs[pin.y_index() - self.coords_mins[1]],
                           flip_rows,
                           self.coords_mins[1], self.coords_maxs[1], flip_cols)
            adjusted_points[pin.coords_indexes()] = pin

        self._defined_points = adjusted_points

        # coords_mins and coords_maxs are each 1-D 2-length arrays of x and y
        self.refresh_mins_maxs()

    def calc_grid_dimensions(self):
        all_dropped_coords = self.points_as_array()
        x_vals = [all_dropped_coords[0, all_dropped_coords[1, :] == y] for y in np.unique(all_dropped_coords[1, :])]
        y_vals = [all_dropped_coords[1, all_dropped_coords[0, :] == x] for x in np.unique(all_dropped_coords[0, :])]
        row_mins = np.array([min(xs) for xs in x_vals])
        col_mins = np.array([min(ys) for ys in y_vals])
        row_maxs = np.array([max(xs) for xs in x_vals])
        col_maxs = np.array([max(ys) for ys in y_vals])

        return row_mins, row_maxs, col_mins, col_maxs

    def refresh_mins_maxs(self):
        all_dropped_coords = self.points_as_array()
        # coords_mins and coords_maxs are each 1-D 2-length arrays of x and y
        self.coords_mins = np.amin(all_dropped_coords, 1)
        self.coords_maxs = np.amax(all_dropped_coords, 1)

    def add_pin_to_output(self, pin, data, count):
        feat = QgsFeature(id=count)
        feat.setGeometry(QgsGeometry.fromPointXY(QgsPointXY(*pin.geoCoords())))
        feat.setAttributes(data)
        self.sink.addFeature(feat)
        # print()
        return count + 1

    def points_as_array(self):
        """
        returns the index coordinates of all points that have been dropped as an array
        the 0 dimension of the array is a point vector (x,y)
        the 1 dimension of the array is a list of the vectors
        """
        return np.stack(self._defined_points.keys(), axis=-1)

    def name(self):
        """
        Returns the algorithm name, used for identifying the algorithm. This
        string should be fixed for the algorithm, and must not be localised.
        The name should be unique within each provider. Names should contain
        lowercase alphanumeric characters only and no spaces or other
        formatting characters.
        """
        return 'Drop Pins Semi-Regularly'

    def displayName(self):
        """
        Returns the translated algorithm name, which should be used for any
        user-visible display of the algorithm name.
        """
        return self.tr(self.name())

    def group(self):
        """
        Returns the name of the group this algorithm belongs to. This string
        should be localised.
        """
        return self.tr(self.groupId())

    def groupId(self):
        """
        Returns the unique ID of the group this algorithm belongs to. This
        string should be fixed for the algorithm, and must not be localised.
        The group id should be unique within each provider. Group id should
        contain lowercase alphanumeric characters only and no spaces or other
        formatting characters.
        """
        return 'Vector creation'

    def tr(self, string):
        return QCoreApplication.translate('Processing', string)

    def createInstance(self):
        return PinDropperAlgorithm()

    # my functions
    def is_complete(self):
        return len(self._loose_ends) == 0

    def population(self):
        return len(self._defined_points)

    def __contains__(self, item):
        return item in self._defined_points

    def __getitem__(self, item):
        assert isinstance(item, tuple)
        assert len(item) == 2
        assert item in self, "%s is not a defined point" % ([item])
        return self._defined_points[item]

    def drop_pin(self, point_candidate):
        '''
        evaluates a point candidate and drops a pin on it if it's within the bounds of the bounding box
        '''
        parent, relation = point_candidate.parent_relation()
        # relation is from the child's POV, so if the parent is to the left of the child, it will be DIRECTION_LEFT
        relation_tup = DIRECTIONS[reverse_direction(relation)]
        approx_geo_dx = relation_tup[0] * self.col_w_geo_dx + relation_tup[1] * self.row_h_geo_dx
        approx_geo_dy = relation_tup[0] * self.col_w_geo_dy + relation_tup[1] * self.row_h_geo_dy

        approx_geo_x = parent.geoX() + approx_geo_dx
        approx_geo_y = parent.geoY() + approx_geo_dy


        # ignore values with approximate values outside the bounding box
        if self.bound_box.contains(QgsPointXY(approx_geo_x, approx_geo_y)):
            if self.near_border(point_candidate.coords_indexes(), approx_geo_x, approx_geo_y):
                return False
            else:
                if self.rate_offset_match is None:
                    self.drop_pin_at(point_candidate, approx_geo_x, approx_geo_y)
                    return True
                else:
                    # print("Sampling target %f, %f" % (parent.geoX(), parent.geoY()))
                    target = self._root_sample if self.compare_from_root else\
                        PinDropperAlgorithm.Sample(parent.geoX(), parent.geoY(), self)
                    assert target.a is not None, "*panicked screaming*\n*breathes*\ncan't sample %s, %s." % \
                                                 (parent.geoX(), parent.geoY())
                    point, rating = self.search(target, approx_geo_x, approx_geo_y)
                    if rating >= self.overlay_match_min_threshold:
                        geo_x, geo_y = point
                    if rating < self.overlay_match_min_threshold and self.is_do_patches():
                        geo_x, geo_y = approx_geo_x, approx_geo_y
                    if rating >= self.overlay_match_min_threshold or self.is_do_patches():
                        self.drop_pin_at(point_candidate, geo_x, geo_y)
                        return True
                    else:
                        # point is hole. will handle later.
                        return False
        else:  # if the loose end is outside the bounds of the network, flag it as a dead end
            point_candidate.status(PinDropperPin.STATUS_DEAD_END)
            return False

    def drop_pin_at(self, point, x, y):
        point.drop_geolocation(x, y)
        self._defined_points[point.coords_indexes()] = point
        new_loose_dict = point.loose_ends_dict()
        self._loose_ends.update(
            {p: new_loose_dict[p]
             for p in new_loose_dict
             if p not in self._loose_ends and p not in self._defined_points}
        )  # avoid adding multiple loose ends for the same x,y pair

    def is_do_patches(self):
        return self.patch_size > 0

    def near_border(self, point, x, y):
        """
        @param point the index coordinates of the point
        @param x the approximate geo x-coordinate of the point
        @param y the approximate geo y-coordinate of the point
        @return true of the point is within one point-radius of the border, false otherwise
        """
        if self.coords_mins is not None \
                and np.all(self.coords_mins <= np.array(point)) \
                and np.all(np.array(point) <= self.coords_maxs):
            return False
        pline = QgsGeometry.fromPolylineXY(self.bound_box.asPolygon()[0])
        # distance = pline.shortestLine(QgsGeometry.fromPointXY(QgsPointXY(x, y))).length()
        # return distance < math.sqrt(math.pow(self.row_h, 2) + math.pow(self.col_w, 2))
        return QgsGeometry.fromPointXY(QgsPointXY(x,y)).within(pline)

    class SearchBox:
        def __init__(self, idx_radius, geo_center, context):
            """
            @param idx_radiuses: an x,y tuple in row, col index scalars of the x and y radii of the search box. does
            NOT have to be int values!
            @param geo_center: an x,y tuple in geocoords (using whatever CRS we're using for everything else) for the center
            of this search box.
            @return a list of x,y geo coordinates to search, with length subdiv^2
            """
            self.radius = idx_radius
            self.geo_center = geo_center
            # row_idx_coords = index within row, so x
            w_rad = idx_radius * context.col_w_stdev
            self.row_idx_coords = np.arange(-w_rad, w_rad, 2 * w_rad / context.search_iter_size)
            # col_idx_coords = index within a column, so y
            h_rad = idx_radius * context.row_h_stdev
            self.col_idx_coords = np.arange(-h_rad, h_rad, 2 * h_rad / context.search_iter_size)
            self.x_geo_coords = geo_center[0] + self.row_idx_coords * context.col_w_geo_dx + self.col_idx_coords * context.row_h_geo_dx
            self.y_geo_coords = geo_center[1] + self.row_idx_coords * context.col_w_geo_dy + self.col_idx_coords * context.row_h_geo_dy
            self.box_coords_list = itertools.product(self.x_geo_coords, self.y_geo_coords)

            self.box_coords_list = filter(lambda p: context.bound_box.contains(QgsPointXY(p[0], p[1])), self.box_coords_list)

        def within(self, geo_x, geo_y):
            return self.x_geo_coords[0] < geo_x < self.x_geo_coords[self.x_geo_coords.shape[0]-1] and \
                   self.y_geo_coords[0] < geo_y < self.y_geo_coords[self.y_geo_coords.shape[0]-1]

        def coords_list(self):
            return self.box_coords_list

        def subsearch(self, center, denominator, context):
            return PinDropperAlgorithm.SearchBox(self.radius / denominator, center, context)

        def __len__(self):
            return len(self.x_geo_coords) * len(self.y_geo_coords)

    def search(self, target_pattern, center_geo_x, center_geo_y):
        '''
        searches for a match of target_pattern around center_geo_x,center_geo_y
        '''
        old_search_box = None
        search_box = None
        for search_level in range(1, 4):
            if search_level > 1:
                old_search_box = search_box
            # print("searching area around %f, %f at radius of %d standard deviations" % (center_geo_x, center_geo_y, search_level))
            search_box = PinDropperAlgorithm.SearchBox(search_level, (center_geo_x, center_geo_y), self)
            point, rating = self.search_area(target_pattern, search_box, old_search_box, self.search_iter_count)
            if rating > self.overlay_match_min_threshold:
                return point, rating
        return None, 0

    def search_area(self, target, search_box, ignore_search_box=None, iters=0):
        '''
        i have no idea how to explain this
        '''
        assert iters >= 0
        best_match = 0
        best_coords = None

        for geo_x, geo_y in search_box.coords_list():
            if ignore_search_box is not None and ignore_search_box.within(geo_x, geo_y):
                continue

            compare = PinDropperAlgorithm.Sample(geo_x, geo_y, self)
            if compare.a is None:
                # entire sample outside raster bounds
                continue

            match = self.rate_offset_match(target, compare)
            if self.precision_bias_coeff != 0:
                # inverse square relationship
                match /= self.precision_bias_coeff * (math.pow(geo_x - search_box.geo_center[0], 2) + math.pow(geo_y - search_box.geo_center[1], 2))
            if match > best_match:
                best_match = match
                best_coords = (geo_x, geo_y)

        if best_coords is None or iters == 0:
            return best_coords, best_match
        else:
            return self.search_area(target, search_box.subsearch(best_coords, 2, self), ignore_search_box, iters-1)

    def calc_margins_clip(self, target, compare):
        clip = np.s_[:, :, :]
        # it's highly unlikely that two samples with the same shape but different margins will be compared
        if target.shape() != compare.shape():
            t_m, c_m = calc_margins(target, compare)
        else:
            t_m = c_m = np.s_[:, :, :]
        t_d = target.data(t_m)
        c_d = compare.data(c_m)
        if t_d.shape != c_d.shape:
            # if off-by-one error, just clip a bit and move on with your life
            if np.all(np.abs(np.array(t_d.shape) - np.array(c_d.shape)) <= 1):
                min_margins = np.minimum(t_d.shape, c_d.shape)
                clip = np.s_[0:min_margins[0] - 1, 0:min_margins[1] - 1, slice(None, None)]
            else:
                clip = None
        return t_m, c_m, clip

    # offset rate algorithms
    def rate_offset_match_gradients(self, target, compare):
        '''
        the most ambitious of my comparison algorithms. attempts to compare the... for lack of a better word,
        derivitives of the two samples.
        '''
        clip = np.s_[:, :, :]
        # it's highly unlikely that two samples with the same shape but different margins will be compared
        if target.shape() != compare.shape():
            t_m, c_m = calc_margins(target, compare)
        else:
            t_m = c_m = np.s_[:, :, :]
        a1 = target.gradients(t_m)
        a2 = compare.gradients(c_m)
        if a1.shape != a2.shape:
            # if off-by-one error, just clip a bit and move on with your life
            if np.all(np.abs(np.array(a1.shape) - np.array(a2.shape)) <= 1):
                min_margins = np.minimum(a1.shape, a2.shape)
                clip = np.s_[0:min_margins[0] - 1, 0:min_margins[1] - 1, ...]
            else:
                return 0

        return 1.0 - (np.mean(np.abs(a1[clip] - a2[clip])) / 255)

    def rate_offset_match_relative_match_count(self, target, compare):
        t_m, c_m, clip = self.calc_margins_clip(target, compare)
        if clip is None:
            return 0

        diff_threshold = 0.1  # arbitarary number!
        diff = target.norm(t_m)[clip] - compare.norm(c_m)[clip]
        match = diff[diff < diff_threshold]
        rating = 1.0 - (np.count_nonzero(match) / target.a.size)
        return rating

    def rate_offset_match_absolute_difference(self, target, compare):
        '''
        takes two matrices of raster data and compares them, rating them by similarity
        Just to be clear I am 100% making this algorithm up.
        @param target the matrix to check match with
        @param compare the matrix to check if it matches target
        @return a value from 0 to 1, where 0 is no match and 1 is 100% match
        '''
        t_m, c_m, clip = self.calc_margins_clip(target, compare)
        if clip is None:
            return 0

        difference = np.abs(compare.data(c_m)[clip] - target.data(t_m)[clip])
        avg_difference = np.mean(difference) / 255
        rating = 1.0 - avg_difference
        return rating

    def rate_offset_match_local_normalized_difference(self, target, compare):
        t_m, c_m, clip = self.calc_margins_clip(target, compare)
        if clip is None:
            return 0
        difference = np.abs(target.norm(t_m)[clip] - compare.norm(c_m)[clip])
        avg_difference = np.mean(difference)
        rating = 1.0 - avg_difference
        return rating

    def rate_offset_match_global_normalized_difference(self, target, compare):
        '''
        takes two matrices of raster data and compares them, rating them by similarity
        Just to be clear I am 100% making this algorithm up.
        @param target the matrix to check match with
        @param compare the matrix to check if it matches target
        @return a value from 0 to 1, where 0 is no match and 1 is 100% match
        '''
        t_m, c_m, clip = self.calc_margins_clip(target, compare)
        if clip is None:
            return 0
        difference = np.abs(compare.data(c_m)[clip] - target.data(t_m)[clip])
        norm_diff = np.stack([difference[:, :, n] / (self.band_ranges[n, 1] - self.band_ranges[n, 0])
                              for n
                              in range(difference.shape[2])], axis=-1)
        avg_difference = np.mean(norm_diff)
        rating = 1.0 - avg_difference
        return rating

    def rate_offset_match_random(self, target, compare):
        '''
        for testing.
        ignores target and compare and returns a random value so that there will be at least one pass rating per
        search. I may have done the math wrong here.
        '''

        return random.random() * (math.pow(self.search_iter_size, 2) / self.overlay_match_min_threshold)


    class Sample:
        def __init__(self, center_geo_x, center_geo_y, context):
            '''
            takes values of the raster at each band in a band in a box surrounding center_geo_x,center_geo_y
            '''
            self._center = (center_geo_x, center_geo_y)

            self._top_left_geo = [center_geo_x - context.overlay_box_radius * context.col_w,
                                  center_geo_y + context.overlay_box_radius * context.row_h]

            self._bottom_right_geo = [center_geo_x + context.overlay_box_radius * context.col_w,
                                      center_geo_y - context.overlay_box_radius * context.row_h]

            x1, y1 = context.asRasterCoords(*self._top_left_geo)
            x2, y2 = context.asRasterCoords(*self._bottom_right_geo)
            # cx, cy = context.asRasterCoords(*self._center)
            # # 0,0 is northwest corner
            # x1 = int(cx - context.overlay_box_radius * context.col_w / context.raster_transform[1])
            # x2 = int(cx + context.overlay_box_radius * context.col_w / context.raster_transform[1])
            # y1 = int(cy - context.overlay_box_radius * context.row_h / context.raster_transform[5])
            # y2 = int(cy + context.overlay_box_radius * context.row_h / context.raster_transform[5])



            # self._top_left_raster = [min(x1, x2), min(y1, y2)]
            # self._bottom_right_raster = [max(x1, x2), max(y1, y2)]
            self._top_left_raster = [x1, y1]
            self._bottom_right_raster = [x2, y2]

            # probably a clever way to do this with fewer lines of code but I'm too lazy to think of it right now
            # assert self._top_left_raster[0] < context.raster_data.shape[0] \
            #        and self._top_left_raster[1] < context.raster_data.shape[1] \
            #        and self._bottom_right_raster[0] >= 0 \
            #        and self._bottom_right_raster[1] >= 0, \
            #        "The bounds of this sample ((%d, %d), (%d, %d), center %d, %d) are entirely outside the bounds of" \
            #        " the provided raster. I didn't think this was actually a thing that could happen but wrote this " \
            #        "message just in case. Frankly I have no idea how you accomplished this. Perhaps the stddev values are too high? " \
            #        "I'm just spitballing here." % (x1, y1, x2, y2, cx, cy)

            if self._top_left_raster[0] >= context.raster_data.shape[0] \
                   or self._top_left_raster[1] >= context.raster_data.shape[1] \
                   or self._bottom_right_raster[0] < 0 \
                   or self._bottom_right_raster[1] < 0:
                # entire sample is outside raster bounds. flag as garbage and move on
                self.a = None
                return

            self.offsets = np.zeros(shape=[NUM_DIRECTIONS], dtype=np.int16)

            if self._top_left_raster[0] < 0:
                self.offsets[DIRECTION_LEFT] = -self._top_left_raster[0]
                self._top_left_raster[0] = 0

            if self._top_left_raster[1] < 0:
                self.offsets[DIRECTION_UP] = -self._top_left_raster[1]
                self._top_left_raster[1] = 0

            if self._bottom_right_raster[0] >= context.raster_data.shape[0]:
                self.offsets[DIRECTION_RIGHT] = context.raster_data.shape[0] - self._bottom_right_raster[0] - 1
                self._bottom_right_raster[0] = context.raster_data.shape[0] - 1

            if self._bottom_right_raster[1] >= context.raster_data.shape[1]:
                self.offsets[DIRECTION_DOWN] = context.raster_data.shape[1] - self._bottom_right_raster[1] - 1
                self._bottom_right_raster[1] = context.raster_data.shape[1] - 1


            self.a = context.raster_data[self._top_left_raster[0]:self._bottom_right_raster[0],
                                         self._top_left_raster[1]:self._bottom_right_raster[1], :]

            if self.a.size == 0:
                print(self._center)
                print(x1, y1, x2, y2)
                print(self._top_left_raster)
                print(self._bottom_right_raster)

            # depending on which match rating algorithm is used, these may or may not ever be needed
            # calculate them on an as-needed basis
            self._min = None
            self._max = None
            self._norm = None
            self._gradients = None
            # middle code. uses RasterDataProvider.block(). could not get to work because there's v. little documentation
            # sample_width = int((2 * self.overlay_box_radius + 1) * self.overlay_box_sampling) # in num samples (pixels)
            # num_bands = self.raster.dataProvider().bandCount()
            # sample_data = np.zeros((sample_width, sample_width, num_bands))
            # point1 = QgsPointXY(center_geo_x - self.overlay_box_radius * self.col_w, center_geo_y - self.overlay_box_radius * self.row_h)
            # point2 = QgsPointXY(center_geo_x + self.overlay_box_radius * self.col_w, center_geo_y + self.overlay_box_radius * self.row_h)
            # for band in range(num_bands):
            #     sample_data[:, :, band] = self.raster.dataProvider().block(band, QgsRectangle(point1, point2), sample_width, sample_width).data()
            # return sample_data

            # old code. box aligns with field rows & columns, but FAR too computationally-intensive
            # # print ("Taking samples of box centered at %f, %f with radius of %d points and %d total samples" %
            # #        (center_geo_x, center_geo_y, sample_radius, sample_width * sample_width))
            #
            # # important note: row_sample_coord and col_sample_coord are in sampling units, not row/col units.
            # # so to change them back to row/col units, you need to divide by self.overlay_box_sampling
            # for row_sample_coord in range(-sample_radius, sample_radius):
            #     for col_sample_coord in range(-sample_radius, sample_radius):
            #         # and viola! x,y coords in raster units! probably!
            #         # (multiply columns by rows and vice versa because it's row coordinate vs. column number and vice versa)
            #         sample_geo_x = center_geo_x + (row_sample_coord * self.col_w_geo_dx + col_sample_coord * self.row_h_geo_dx) / self.overlay_box_sampling
            #         sample_geo_y = center_geo_y + (row_sample_coord * self.col_w_geo_dy + col_sample_coord * self.row_h_geo_dy) / self.overlay_box_sampling
            #         # print("Sample raster bands 1 - %d at %f,%f" % (num_bands, sample_geo_x, sample_geo_y))
            #         bands = self.raster.dataProvider().identify(QgsPointXY(sample_geo_x, sample_geo_y), QgsRaster.IdentifyFormatValue).results()
            #         bands = [bands[k] for k in bands]
            #         sample_data[row_sample_coord + sample_radius, col_sample_coord + sample_radius, :] = bands
            # return sample_data

        def data(self, margins=np.s_[:, :]):
            return self.a[margins]

        def min(self, band=None):
            if self._min is None:
                self._min = np.amin(self.a, (0, 1))
            return self._min[band] if band is not None else self._min

        def max(self, band=None):
            if self._max is None:
                self._max = np.amax(self.a, (0, 1))
            return self._max[band] if band is not None else self._max

        def shape(self, margins=np.s_[:, :]):
            return self.data(margins).shape

        def bands(self):
            return self.a.shape[2]

        def norm(self, margins=np.s_[:, :]):
            if self._norm is None:
                self._norm = np.stack([self.a[:, :, n] / (self.max(n) - self.min(n))
                                      for n in range(self.bands())],
                                      axis=-1)
            return self._norm[margins]

        def gradients(self, margins=np.s_[:, :]):
            if self._gradients is None:
                self._gradients = gradient(self.a)
            return self._gradients[margins]

        def __str__(self):
            return "Sample of the raster matrix from %s to %s, corresponding to geo-coords %s, %s" % \
                   (self._top_left_raster, self._bottom_right_raster, self._top_left_geo, self._bottom_right_geo)

        def export(self, context):
            driver = gdal.GetDriverByName("GTiff")
            transform = list(context.raster_transform)
            transform[0] = self._top_left_geo[0]
            transform[3] = self._top_left_geo[1]

            fn = "/home/josh/AgriTech/Gold Lab/test files/%f_%f.tif" % self._center
            outdata = driver.Create(fn, self.a.shape[1], self.a.shape[0], bands=3, eType=gdal.GDT_UInt16)
            outdata.SetGeoTransform(transform)
            outdata.SetProjection(context.raster.crs().toWkt())
            for band in range(self.bands()):
                arr = self.data()[:, :, band].astype(np.uint16)
                outdata.GetRasterBand(band + 1).WriteArray(arr)
            outdata.FlushCache()

            fn = "/home/josh/AgriTech/Gold Lab/test files/%f_%f_norm.tif" % self._center
            outdata = driver.Create(fn, self.a.shape[1], self.a.shape[0], bands=3, eType=gdal.GDT_Float32)
            outdata.SetGeoTransform(transform)
            outdata.SetProjection(context.raster.crs().toWkt())
            for band in range(self.bands()):
                outdata.GetRasterBand(band + 1).WriteArray(self.norm()[:, :, band].astype(np.float32))
            outdata.FlushCache()

            fn = "/home/josh/AgriTech/Gold Lab/test files/%f_%f_grad.tif" % self._center
            arr = np.average(self.gradients(), axis=3)
            outdata = driver.Create(fn, arr.shape[1], arr.shape[0], bands=3, eType=gdal.GDT_Float32)
            outdata.SetGeoTransform(transform)
            outdata.SetProjection(context.raster.crs().toWkt())
            for band in range(self.bands()):
                outdata.GetRasterBand(band + 1).WriteArray(arr[:, :, band].astype(np.float32))
            outdata.FlushCache()

            outdata = None
            driver = None

            print(self._top_left_geo, self._bottom_right_geo)

    def asRasterCoords(self, x_geo, y_geo):
        x = (x_geo - self.raster_transform[0]) / self.raster_transform[1]
        y = (y_geo - self.raster_transform[3]) / self.raster_transform[5]

        # raster_bounds = self.raster.dataProvider().extent()
        # x_rel = x_geo - raster_bounds.xMinimum()
        # x = (x_rel / raster_bounds.width()) * self.raster_data.shape[0]
        # y_rel = y_geo - raster_bounds.yMinimum()
        # y = (y_rel / raster_bounds.height()) * self.raster_data.shape[1]

        return int(round(x)), int(round(y))  # "int(round(...)) is redundant but the program gets mad if I don't

    def geo_coords_distance(self, c1, c2, absolute=False, single_value=False):
        if not isinstance(c1, PinDropperPin):
            c1 = self[c1]
        if not isinstance(c2, PinDropperPin):
            c2 = self[c2]

        distance = np.array(c1.geoCoords()) - np.array(c2.geoCoords())
        if absolute:
            distance = np.abs(distance)
        if single_value:
            distance = np.linalg.norm(distance)
        return distance

    def idx_distance(self, c1, c2, absolute=False, single_value=False):
        if isinstance(c1, PinDropperPin):
            c1 = c1.coords_indexes()
        if isinstance(c2, PinDropperPin):
            c2 = c2.coords_indexes()

        distance = np.array(c1) - np.array(c2)
        if absolute:
            distance = np.abs(distance)
        if single_value:
            distance = np.linalg.norm(distance)
        return distance

class PinDropperPin:

    STATUS_PIN = 0
    STATUS_LOOSE_END = 1
    STATUS_DEAD_END = 2

    def __init__(self, x_index, y_index, parent, origin):
        # x and y are immutable
        self._x_index = x_index
        self._y_index = y_index
        self._status = PinDropperPin.STATUS_LOOSE_END
        self._geoX = None
        self._geoY = None
        self._adjs = [None for i in range(NUM_DIRECTIONS)]
        if parent is not None: # parent will be none for the root pin, or for patched holes
            self._adjs[origin] = parent

    def drop_geolocation(self, geoX, geoY):
        self.geoX(geoX)
        self.geoY(geoY)
        self.status(PinDropperPin.STATUS_PIN)

        for i in range(NUM_DIRECTIONS):
            if self._adjs[i] is None:
                self._adjs[i] = PinDropperPin(self.x_index() + DIRECTIONS[i][0],
                                              self.y_index() + DIRECTIONS[i][1],
                                              self,
                                              reverse_direction(i)
                                              )

    def parent_relation(self):
        """
        returns a tuple of the parent of this pin and its relation, assuming this pin is a loose end.
        """
        assert self.status() == PinDropperPin.STATUS_LOOSE_END
        i = list(filter(lambda x: self._adjs[x] is not None, range(NUM_DIRECTIONS)))[0]
        return self._adjs[i], i

    def loose_ends(self):
        return filter(lambda x: x.status() == PinDropperPin.STATUS_LOOSE_END, self.adjs())

    def loose_ends_dict(self):
        loose_ends = self.loose_ends()
        return {x.coords_indexes(): x for x in loose_ends}

    def status(self, new_status=-1):
        """
        retrieves or assigns pin status
        """
        if new_status > -1:
            self._status = new_status
        else:
            return self._status

    def x_index(self):
        return self._x_index

    def y_index(self):
        return self._y_index

    def coords_indexes(self):
        return self._x_index, self._y_index

    def left(self):
        return self._adjs[DIRECTION_LEFT]

    def up(self):
        return self._adjs[DIRECTION_UP]

    def right(self):
        return self._adjs[DIRECTION_RIGHT]

    def down(self):
        return self._adjs[DIRECTION_DOWN]

    def adjs(self):
        return [pin for pin in self._adjs]  # copy, don't pass a reference to the list

    def geoX(self, new_x=None):
        if new_x is not None:
            self._geoX = new_x
        else:
            return self._geoX

    def geoY(self, new_y=None):
        if new_y is not None:
            self._geoY = new_y
        else:
            return self._geoY

    def geoCoords(self):
        return self.geoX(), self.geoY()

    def merge_with_loose_end(self, loose_end):
        assert self.status() == PinDropperPin.STATUS_PIN
        assert loose_end.status() == PinDropperPin.STATUS_LOOSE_END
        assert self.coords_indexes() == loose_end.coords_indexes()

        loose_end_parent, loose_end_parent_rel = loose_end.parent_relation()
        if self._adjs[loose_end_parent_rel] is None:    # i'm not sure why this is ever the case but I could either
                                                        # spend hours on figuring that out or put this if-statement here
            self._adjs[loose_end_parent_rel] = loose_end_parent
        else:
            print("self: %s;\n loose_end_parent_rel: %d;\n self._adjs[loose_end_parent_rel]: %s;\n self.coords_indexes(): %s;\n loose_end: %s;\n"
                  "loose_end_parent: %s" %
                  (self, loose_end_parent_rel, self._adjs[loose_end_parent_rel], str(self.coords_indexes()), loose_end, loose_end_parent))
            assert False

    def relativize(self, xmin, xmax, flip_x, ymin, ymax, flip_y):
        if not flip_x:
            self._x_index = self._x_index - xmin + 1  # index from 1
        else:
            self._x_index = xmax - self._x_index + 1  # index from 1
        if not flip_y:
            self._y_index = self._y_index - ymin + 1  # index from 1
        else:
            self._y_index = ymax - self._y_index + 1  # index from 1

    def __str__(self):
        return "Point with status %d at indexes %d, %d and geo coords %s with adjacent statuses %s, %s, %s, %s" \
               % (self.status(), *self.coords_indexes(),
                  str(self.geoCoords() if self.geoX() is not None else "No geo coords"),
                  *[str(p.status()) if p is not None else "None" for p in self._adjs])


def reverse_direction(direction):
    return int((direction + (NUM_DIRECTIONS / 2)) % NUM_DIRECTIONS)


def match_index(l, regex):
    p = re.compile(regex)
    for i in range(len(l)):
        m = p.match(l[i])
        if m is not None:
            return l[i], i
    return None, -1


def gradient(a):    
    '''
    @param a:  a matrix of (n x p x q), where n and p are the width and height. r will be essentially ignored
    @return an array of shape (n - 2r, p - 2r, q, 2) of x and y magnitudes of the gradient vectors. [:,:,:,0] is x
        magnitudes, [:,:,:,1] is y-magniutes. algorithm is incomplete; only does partial use of non-row and column
        differences. this is a deliberate choice for computational power reasons
    '''
    r = 2
    d = 2*r+1
    w = a.shape[0]
    h = a.shape[1]
    vectors = np.zeros((w - 2*r, h - 2*r, a.shape[2], d, d))
    base = a[r:-r, r:-r, :]
    for x in range(d):
        for y in range(d):
            shift_x = x - (r + 1)
            shift_y = y - (r + 1)
            if shift_x == 0 and shift_y == 0:
                # trying to take gradient from (0,0) rel position
                continue
            shift = a[x:x + (w - 2*r), y: y + (h - 2*r), :]
            vectors[..., x, y] = (base - shift) / (math.pow(shift_x, 2) + math.pow(shift_y, 2))
    x_grad = np.sum(vectors, axis=3)[:, :, :, r + 1]
    y_grad = np.sum(vectors, axis=4)[:, :, :, r + 1]

    return np.stack((x_grad, y_grad), axis=-1)


def calc_margins(sample1, sample2):
    """
    given two Sample objects of different shapes, calculates the margins to apply to each one
    to give to matrices of the same shape and the same area
    """
    return as_margins(np.maximum(sample2.offsets - sample1.offsets, np.zeros(shape=[NUM_DIRECTIONS], dtype=np.int16))),\
           as_margins(np.maximum(sample1.offsets - sample2.offsets, np.zeros(shape=[NUM_DIRECTIONS], dtype=np.int16)))


def as_margins(m):
    return np.s_[
            m[DIRECTION_LEFT]:-m[DIRECTION_RIGHT] if m[DIRECTION_RIGHT] > 0 else None,
            m[DIRECTION_DOWN]:-m[DIRECTION_UP] if m[DIRECTION_UP] > 0 else None,
    :]

